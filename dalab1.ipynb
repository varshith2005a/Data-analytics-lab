{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc3KRb/qD6O0YUNwU9wHS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshith2005a/Data-analytics-lab/blob/main/dalab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n",
        "Data preprocessing is the process of transforming raw, often messy data into a clean and understandable format that is suitable for analysis or machine learning models.\n",
        "\n",
        "Real-world data is often incomplete, inconsistent, and lacking in certain behaviors or trends, and is likely to contain many errors.\n",
        "\n",
        "Handling Missing Values: Filling in gaps (imputation) or removing incomplete rows.\n",
        "\n",
        "Noisy Data: smoothing out error and outliers (binning, regression, clustering).\n",
        "\n",
        "Outlier Removal: Identifying data points that are statistically improbable (e.g., Age = 200).\n",
        "\n",
        "Identifying redundancy involves finding duplicate records or attributes that convey the same information (e.g., storing both \"Age\" and \"Date of Birth\").\n",
        "\n",
        "Elimination removes these repetitive instances to reduce dataset size, ensure consistency, and prevent the model from becoming biased toward frequent data points.\n",
        "\n"
      ],
      "metadata": {
        "id": "5lsvonhs7nDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hmV66YKr7I-M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Dataset"
      ],
      "metadata": {
        "id": "iOUqB7Tj-h4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data={\n",
        "    'Name':['Alice','Bob','Alice','David','Eve','Frank','Grace','Heidi'],\n",
        "    'Age':[25,np.nan,25,45,120,30,np.nan,35],\n",
        "    'Salary':[50000,60000,50000,80000,55000,58000,62000,2000000],\n",
        "    'City':['NY','LA','NY','Chicago','Houston','Phoenix','NY','Seattle']\n",
        "}\n",
        "df=pd.DataFrame(data)\n",
        "print(\"--- ORIGINAL DATAFRAME ---\")\n",
        "print(df)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXzjpbTf7lw1",
        "outputId": "5f9e8568-5432-458b-96ab-f41ec1d990c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ORIGINAL DATAFRAME ---\n",
            "    Name    Age   Salary     City\n",
            "0  Alice   25.0    50000       NY\n",
            "1    Bob    NaN    60000       LA\n",
            "2  Alice   25.0    50000       NY\n",
            "3  David   45.0    80000  Chicago\n",
            "4    Eve  120.0    55000  Houston\n",
            "5  Frank   30.0    58000  Phoenix\n",
            "6  Grace    NaN    62000       NY\n",
            "7  Heidi   35.0  2000000  Seattle\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling missing values"
      ],
      "metadata": {
        "id": "xXQ99vPS-mSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Missing values per column:\\n{df.isnull().sum()}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQs6Odw4-foy",
        "outputId": "12afcace-12c8-4e04-83be-8acbb5bf6d89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "Name      0\n",
            "Age       2\n",
            "Salary    0\n",
            "City      0\n",
            "dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped=df.dropna()\n",
        "print(\"1.Shape after dropping rows with NaNs:\",df_dropped.shape)\n",
        "print(df_dropped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPOx21h4-7KM",
        "outputId": "66759706-65c7-4da4-d77a-306688de3474"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.Shape after dropping rows with NaNs: (6, 4)\n",
            "    Name    Age   Salary     City\n",
            "0  Alice   25.0    50000       NY\n",
            "2  Alice   25.0    50000       NY\n",
            "3  David   45.0    80000  Chicago\n",
            "4    Eve  120.0    55000  Houston\n",
            "5  Frank   30.0    58000  Phoenix\n",
            "7  Heidi   35.0  2000000  Seattle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed=df.copy()\n",
        "median_age=df_imputed['Age'].median()\n",
        "df_imputed['Age']=df_imputed['Age'].fillna(median_age)\n",
        "print(\"2. Filled missing Age with median({median_age})\")\n",
        "print(df_imputed)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3mCZhnR_YOI",
        "outputId": "dbcdc2c6-497e-4b9c-c5ef-a42b192dd9cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Filled missing Age with median({median_age})\n",
            "    Name    Age   Salary     City\n",
            "0  Alice   25.0    50000       NY\n",
            "1    Bob   32.5    60000       LA\n",
            "2  Alice   25.0    50000       NY\n",
            "3  David   45.0    80000  Chicago\n",
            "4    Eve  120.0    55000  Houston\n",
            "5  Frank   30.0    58000  Phoenix\n",
            "6  Grace   32.5    62000       NY\n",
            "7  Heidi   35.0  2000000  Seattle\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOISE DETECTION & REMOVAL(Outliers)"
      ],
      "metadata": {
        "id": "vXZyhsxFAFvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df_imputed['Age'].quantile(0.25)\n",
        "Q3 = df_imputed['Age'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "print(f\"Age Bounds: {lower_bound} to {upper_bound}\")\n",
        "df_clean_noise = df_imputed[\n",
        "    (df_imputed['Age'] >= lower_bound) &\n",
        "    (df_imputed['Age'] <= upper_bound)\n",
        "]\n",
        "print(\"Rows removed (Noise):\")\n",
        "print(df_imputed[~df_imputed.index.isin(df_clean_noise.index)])\n",
        "print(\"\\n\")\n",
        "print(\"Dataset after noise removal\")\n",
        "print(df_clean_noise)"
      ],
      "metadata": {
        "id": "x1aZa4AHAOIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d571aa2c-b5b2-4f12-a49f-b8a8bce93e46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age Bounds: 15.625 to 50.625\n",
            "Rows removed (Noise):\n",
            "  Name    Age  Salary     City\n",
            "4  Eve  120.0   55000  Houston\n",
            "\n",
            "\n",
            "Dataset after noise removal\n",
            "    Name   Age   Salary     City\n",
            "0  Alice  25.0    50000       NY\n",
            "1    Bob  32.5    60000       LA\n",
            "2  Alice  25.0    50000       NY\n",
            "3  David  45.0    80000  Chicago\n",
            "5  Frank  30.0    58000  Phoenix\n",
            "6  Grace  32.5    62000       NY\n",
            "7  Heidi  35.0  2000000  Seattle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDENTIFYING & ELIMINATING DATA REDUNDANCY"
      ],
      "metadata": {
        "id": "4cULY-tdBBXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = df_clean_noise[df_clean_noise.duplicated(keep=False)]\n",
        "print(\"Duplicate Rows found:\")\n",
        "print(duplicates)\n",
        "df_final = df_clean_noise.drop_duplicates(keep='first')\n",
        "print(\"\\n--- FINAL CLEANED DATAFRAME ---\")\n",
        "print(df_final)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2rAml45BEK9",
        "outputId": "8a11d006-cc0f-4d36-8075-983ce8561219"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate Rows found:\n",
            "    Name   Age  Salary City\n",
            "0  Alice  25.0   50000   NY\n",
            "2  Alice  25.0   50000   NY\n",
            "\n",
            "--- FINAL CLEANED DATAFRAME ---\n",
            "    Name   Age   Salary     City\n",
            "0  Alice  25.0    50000       NY\n",
            "1    Bob  32.5    60000       LA\n",
            "3  David  45.0    80000  Chicago\n",
            "5  Frank  30.0    58000  Phoenix\n",
            "6  Grace  32.5    62000       NY\n",
            "7  Heidi  35.0  2000000  Seattle\n"
          ]
        }
      ]
    }
  ]
}